{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Generative Adversarial Network on MNIST\n",
    "\n",
    "The goal of this assignment is to train a GAN (Generative Adversarial Network) model using PyTorch on the MNIST dataset to generate digit images. The MNIST dataset consists of grayscale handwritten digit images with a resolution of 28×28 pixels.\n",
    "\n",
    "For this task, you are required to complete the following steps:\n",
    "\n",
    "> 1. Implement the main components in the Generator and Discriminator. (in Step-2)\n",
    "> 2. Define the loss function and optimizers (in Step 3).\n",
    "> 3. Complete the training loop (in Step 4), including: \\\n",
    "    (a) Labels for real images and fake images when training the discriminator, \\\n",
    "    (b) Calculation of the discriminator’s loss for real images, \\\n",
    "    (c) Calculation of the discriminator’s loss for fake images, \\\n",
    "    (d) Calculation of the generator’s loss.\n",
    "> 4. Plot the training loss curves (in Step 5).\n",
    "> 5. Generate and save 25 images using the trained generator (in Step 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Step-1: import packages and load datasets\n",
    "        For MNIST dataset, we can directly load it from torchvision\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL.Image as Image \n",
    "\n",
    "# Hyper-parameters\n",
    "batch_size = 128\n",
    "latent_dim = 100\n",
    "lr = 0.0002\n",
    "epochs = 50\n",
    "device = \"cpu\"  # If your device has a GPU, you can change 'cpu' to 'cuda'.\n",
    "\n",
    "\n",
    "# Create directories for saving the outputs\n",
    "os.makedirs(\"gan_images\", exist_ok=True)\n",
    "os.makedirs(\"gan_models\", exist_ok=True)\n",
    "\n",
    "# Data processing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 2: implement the generator and discriminator\n",
    "\"\"\"\n",
    "\n",
    "# Define the Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100,):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        ############# Start of your code ###################\n",
    "        # Note: You need to insert activation functions at appropriate locations\n",
    "        # TODO-1\n",
    "        self.model = nn.Sequential(\n",
    "            \n",
    "        )\n",
    "        \n",
    "        ############## End of your code ####################\n",
    "    \n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 1, 28, 28)\n",
    "        return img\n",
    "\n",
    "\n",
    "# Define the Discriminator Network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        ############# Start of your code ###################\n",
    "        # Note: You need to insert activation functions at appropriate locations\n",
    "        # TODO-1\n",
    "        self.model = nn.Sequential(\n",
    "            \n",
    "        )\n",
    "        \n",
    "        ############## End of your code ####################\n",
    "        \n",
    "    def forward(self, img):\n",
    "        flattened = img.view(img.size(0), -1)\n",
    "        validity = self.model(flattened)\n",
    "        return validity.squeeze(1)\n",
    "\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 3: define the loss functions and optimizers for the generator and discriminator\n",
    "\"\"\"\n",
    "\n",
    "############# Start of your code ###################\n",
    "# TODO-2\n",
    "\n",
    "adv_loss_fun = None\n",
    "optimizer_G = None\n",
    "optimizer_D = None\n",
    "\n",
    "############## End of your code ####################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 4: implement entire process of training a GAN\n",
    "\"\"\"\n",
    "\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "        \n",
    "        ############# Start of your code ###################\n",
    "        # define labels for real images and fake images\n",
    "        # TODO-3\n",
    "\n",
    "        real = None\n",
    "        fake = None \n",
    "        \n",
    "        ############## End of your code ####################        \n",
    "        \n",
    "        real_imgs = imgs.to(device)\n",
    "        \n",
    "        \n",
    "        # Training the discriminator\n",
    "        ############# Start of your code ###################\n",
    "        # freeze the parameters in the generator and activate the parameters in the discriminator \n",
    "        # TODO-3\n",
    "\n",
    "        ############## End of your code ####################\n",
    "\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        ############# Start of your code ###################\n",
    "        # Loss of discriminting real images\n",
    "        # TODO-3\n",
    "        real_loss = None \n",
    "        ############## End of your code ####################\n",
    "        \n",
    "        \n",
    "        # Generating fake images\n",
    "        z = torch.randn(imgs.size(0), latent_dim, device=device)\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "\n",
    "        ############# Start of your code ###################\n",
    "        # Loss of discriminting generated images\n",
    "        # TODO-3\n",
    "        fake_loss = None \n",
    "        ############## End of your code ####################\n",
    "        \n",
    "        # Overall loss\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "\n",
    "        \n",
    "        # Training the generator\n",
    "\n",
    "        ############# Start of your code ###################\n",
    "        # freeze the parameters in the discriminator and activate the parameters in the generator \n",
    "        # TODO-3\n",
    "\n",
    "        ############## End of your code ####################\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        z = torch.randn(imgs.size(0), latent_dim, device=device)\n",
    "        gen_imgs = generator(z)  # Generating fake images\n",
    "\n",
    "        ############# Start of your code ###################\n",
    "        # Loss of generating images\n",
    "        # TODO-3\n",
    "        g_loss = None \n",
    "        ############## End of your code ####################\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Recording the training process\n",
    "        d_losses.append(d_loss.item())\n",
    "        g_losses.append(g_loss.item())\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(train_loader)}] \"\n",
    "                    f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n",
    "    \n",
    "    # Save the generated images at the end of each epoch.\n",
    "    save_image(gen_imgs.data[:25], f\"gan_images/epoch_{epoch}.png\", nrow=5, normalize=True)\n",
    "    \n",
    "    # Save the checkpoint\n",
    "    torch.save(generator.state_dict(), f\"gan_models/generator_epoch_{epoch}.pth\")\n",
    "    torch.save(discriminator.state_dict(), f\"gan_models/discriminator_epoch_{epoch}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 5: Plot the training loss curve\n",
    "\"\"\"\n",
    "\n",
    "############# Start of your code ###################\n",
    "# Plot the training loss curve\n",
    "# TODO-4\n",
    "\n",
    "############## End of your code ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 6: Generate images using a trained generator, and save them\n",
    "\"\"\"\n",
    "\n",
    "############# Start of your code ###################\n",
    "# TODO-5 \n",
    "num_examples=25\n",
    "\n",
    "\n",
    "############## End of your code ####################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internvl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
